The Internet is flooded with a huge amount of personal opinion. This ranges from a blog post on the recent U.S. election to a short review for a purchased item on an e-commerce website. Understanding what is in the mind of the population may bring a significant monetary or political value, and this gave rise to research in {\em sentiment analysis}, an application of natural language processing which aims to mine subjective information.

In particular, we look at the task of polarity classification of movie reviews. The polarity classification is a problem which concerns with identifying whether a given review has a positive or negative overall sentiment. The bag of words model is a simple representation which can used in polarity classification, where a text is represented by a set of words it contains. As it ignores the syntactic structure of the text completely, much of semantic information is lost. For instance, in the bag of words model, \textit{Alice loves Bob.} and \textit{Bob loves Alice.} have exactly the same representation, as the words they contain are identical, even though the semantics they convey are very different.

In this report, we attempt to recover the effect of negation which is otherwise lost in the bag of words model. For example, the sentiment of a sentence \textit{The movie was not exciting.} is negative, even though it contains a positive word \textit{exciting}, because of  \textit{not}. In this report, we refer to words which mark a negation as \emph{negation term}. Intuitively, such information can be used to improve the performance of the classifier which uses the bag of words model. However, it would be an approximation to say a negation term affects all the words in the sentence. For instance \textit{not} in \textit{It was not scary, so I loved it.} only contributes to the semantics of the main clause. In other words, the effect of negation terms are limited to some scope.

In this report, I explore various heuristics that identify the scope of the negation. I use these heuristics to improve two classifiers which uses bag of words model. One is a symbolic classifier, originally presented in~\citep{wilson2005recognizing}, which uses a lexicon where each word is associated with a sentiment it represents. The other is a Naive Bayes classifier described in \cite{pang2002thumbs}. The lexicon and the dataset was provided on the framework of the module L90 in MPhil Advanced Computer Science at University of Cambridge.

The report proceeds as following: Section 2 describes the approaches presented in~\citep{wilson2005recognizing} and~\citep{pang2002thumbs} in detail; Section 3 describes the scoping heuristics examined; Section 4 describes implementation choices made while setting up the experiment, including how negated terms are treated by each classifier; Finally, Section 5 discusses the results obtained from this experiment.

