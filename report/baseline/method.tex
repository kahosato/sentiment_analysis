%- python 2.7
%- tokenisation
%- 10-cross validation
%	- randomise
This section describes implementation choices made while replicating the methods described in Section \ref{sec:background}.
\subsection{Tokenisation}
In this section, the process of converting a input documents into a stream of tokens is described.
A document is first split into sentences, which get tokenised separately.
The first letter of a sentence is capitalised, and it gets split at the white spaces to give the initial list of tokens.
Then, 11 rules are applied sequentially to each token in the list. Each rule is associated with a regular expression, and only if the token matches the pattern the rule gets applied. Most rules split at the punctuation which becomes its own token, with the following exceptions.
\begin{itemize}
\item Do not split at hyphens if it contains non-alphabetical character.
(e.g. ``long-term'' $\rightarrow$ [``long'', ``-'', ``term''], ``3-G21'' $\rightarrow$ [``3-G21''])
\item Split ``'ll'' and add a token ``will'' instead.
(e.g. ``you'll'' $\rightarrow$ [``you'', ``will''])
\item Split ``n't'' and add a token ``not'' instead.
(e.g. ``don't'' $\rightarrow$ [``do'', ``not''])
\item Split ``'ve'' and add a token ``have'' instead.
(e.g. ``you've'' $\rightarrow$ [``you'', ``have''])
\end{itemize}
Note that all the punctuations are kept in the resulting tokens.
\subsection{Cross Validation}
I use k-fold cross validation to evaluate and compare the performance of models.
The list of all the documents are {\em randomly} partitioned into $k$ equal-sized fold.
The model is tested on each fold after being trained on the remaining $k-1$ folds.
\subsection{Symbolic Approach}
\subsubsection{Sentiment Score}
I use the magnitude of $1$ for a word marked ``strong'' and $0.5$ for ``weak''. For words marked ``neutral'' or ``both'' I assign the sentiment score of $0$.
\subsection{Naive Bayes Classifier}
\subsection{Features}
I use unigrams without stemming or stoplist.
They are admittedly very simple, which I believe is appropriate for a baseline system.
\subsection{Smoothing}
For the smoothing constant, I use 1 as in \cite{pang2002thumbs}.